# sample crontab entry

# Every minute download files for all car2go cities of interest and cache them
# in files named "current_{city}" so they can be used by web tools.
# Replace the ellipses with actual path, optionally replace "car2go" with
# another supported system.

*/1 * * * * python3 .../electric2go/download.py car2go all >> .../electric2go/data/cronlog-car2go
*/1 * * * * python3 .../electric2go/download.py drivenow all >> .../electric2go/data/cronlog-drivenow

# Optionally, archive the downloaded information, by adding "archive" param:

*/1 * * * * python3 .../electric2go/download.py car2go all archive >> .../electric2go/data/cronlog-car2go
*/1 * * * * python3 .../electric2go/download.py drivenow all archive >> .../electric2go/data/cronlog-drivenow

# Daily, at 1 am server time, tarball+gzip up previous day's archived files
# into .../electric2go/data/car2go-archives/.
# A tarball is a lot easier to move around than 1440 individual files,
# and normalize.py can process it directly.
# The remove step (&& rm {}*) saves a lot of drivespace, but can be omitted
# if you'd like to be super-sure you have all the data.
# To adapt for other systems, just replace the three occurrences of "car2go".
# This command is pretty hacky, can probably be done better,
# but it seems to work well at least on Debian Wheezy.

0 1 * * * cd .../electric2go/data/car2go/ && find . -type f -name "`date -d 'yesterday 13:00' '+*\%Y-\%m-\%d*'`" | awk -F '--' '{print $1}' | sort -u | xargs -i sh -c "tar cfz ../car2go-archives/{}.tgz {}* && rm {}*" >> .../electric2go/data/cronlog-car2go-archives
10 1 * * * cd .../electric2go/data/drivenow/ && find . -type f -name "`date -d 'yesterday 13:00' '+*\%Y-\%m-\%d*'`" | awk -F '--' '{print $1}' | sort -u | xargs -i sh -c "tar cfz ../drivenow-archives/{}.tgz {}* && rm {}*" >> .../electric2go/data/cronlog-drivenow-archives
